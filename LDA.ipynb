{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Upendra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "#Gensim & nltk\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "from gensim.models import HdpModel\n",
    "#from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer  \n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from gensim.parsing.preprocessing import strip_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words ={'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very','|','advertisement','new','york','times','would','m','re','mr','ms','look','say','see','put','take','told','might','well','go','still','made','much','way','u','us','like','ve','get','said','also','could','use','next','week','going','according','back','since','around','far','used','less','often','using','d','make','need','many','one','two','three','come','among','another','last','says','based','later','start','even','odd','o','dr','across','really','every','year','years','think','know','percent','want','called','city','right','including','high','part','good','day','life','big','news','help','group','long',\n",
    "'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than','-',';','via'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    lancaster_stemmer = LancasterStemmer()\n",
    "    return lancaster_stemmer.stem(text)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        try:\n",
    "            token=re.sub(\" \\d+\", \" \", token)\n",
    "            if token not in stop_words and token.isalpha() and len(token) > 3:\n",
    "                result.append(token)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('redditPost.csv')\n",
    "data2 = pd.read_excel('comment_reddit.xlsx')\n",
    "frames = [data1.title, data2.Comments]\n",
    "result = pd.concat(frames)\n",
    "processed_docs = result.map(preprocess)\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5, )#keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.033*\"consulting\" + 0.018*\"time\" + 0.017*\"gmat\" + 0.017*\"interview\" + '\n",
      "  '0.016*\"tech\" + 0.013*\"people\" + 0.013*\"experience\" + 0.011*\"work\" + '\n",
      "  '0.011*\"company\" + 0.010*\"full\"'),\n",
      " (1,\n",
      "  '0.023*\"practice\" + 0.020*\"gmat\" + 0.018*\"tech\" + 0.017*\"months\" + '\n",
      "  '0.017*\"didn\" + 0.017*\"west\" + 0.014*\"coast\" + 0.014*\"tests\" + 0.013*\"work\" '\n",
      "  '+ 0.013*\"anderson\"'),\n",
      " (2,\n",
      "  '0.031*\"school\" + 0.027*\"work\" + 0.024*\"thanks\" + 0.021*\"experience\" + '\n",
      "  '0.020*\"gmat\" + 0.016*\"hours\" + 0.014*\"roles\" + 0.012*\"people\" + '\n",
      "  '0.012*\"prep\" + 0.010*\"advice\"'),\n",
      " (3,\n",
      "  '0.018*\"time\" + 0.018*\"consulting\" + 0.017*\"post\" + 0.015*\"experience\" + '\n",
      "  '0.012*\"business\" + 0.011*\"people\" + 0.011*\"work\" + 0.010*\"programs\" + '\n",
      "  '0.010*\"industry\" + 0.010*\"online\"'),\n",
      " (4,\n",
      "  '0.035*\"work\" + 0.019*\"school\" + 0.016*\"people\" + 0.013*\"class\" + '\n",
      "  '0.013*\"career\" + 0.011*\"students\" + 0.011*\"pretty\" + 0.010*\"time\" + '\n",
      "  '0.009*\"experience\" + 0.009*\"summer\"'),\n",
      " (5,\n",
      "  '0.022*\"people\" + 0.020*\"consulting\" + 0.014*\"program\" + 0.013*\"experience\" '\n",
      "  '+ 0.012*\"didn\" + 0.011*\"better\" + 0.011*\"harvard\" + 0.010*\"yeah\" + '\n",
      "  '0.009*\"recruiting\" + 0.008*\"though\"'),\n",
      " (6,\n",
      "  '0.031*\"school\" + 0.024*\"program\" + 0.022*\"time\" + 0.020*\"work\" + '\n",
      "  '0.013*\"schools\" + 0.012*\"offer\" + 0.012*\"home\" + 0.011*\"network\" + '\n",
      "  '0.010*\"interview\" + 0.010*\"post\"'),\n",
      " (7,\n",
      "  '0.046*\"gmat\" + 0.037*\"schools\" + 0.016*\"programs\" + 0.015*\"sure\" + '\n",
      "  '0.012*\"different\" + 0.012*\"undergrad\" + 0.012*\"class\" + 0.011*\"work\" + '\n",
      "  '0.011*\"school\" + 0.011*\"scores\"')]\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=1400,\n",
    "                                           passes=1,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.736242316900213\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "print(lda_model.log_perplexity(bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list=[]\n",
    "topic_list=[]\n",
    "weight_list=[]\n",
    "\n",
    "i=0\n",
    "for doc in processed_docs:\n",
    "    doc_list.append(doc)\n",
    "    doc=dictionary.doc2bow(doc)\n",
    "    evaluated_doc=lda_model[doc][0]\n",
    "    highest_score=sorted(evaluated_doc,key=lambda x: x[1], reverse=True)[0]\n",
    "    topic_list.append(highest_score[0])\n",
    "    weight_list.append(highest_score[1])\n",
    "    i=i+1\n",
    "topic1={'topic':topic_list}\n",
    "topic = pd.DataFrame(topic1)  \n",
    "weight1={'weight': weight_list}\n",
    "weight = pd.DataFrame(weight1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.assign(topic=topic.values)\n",
    "result = result.assign(weight=weight.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                0  topic    weight\n",
      "0                  How to submit a profile review      1  0.435085\n",
      "1                                R2 Status Thread      0  0.136094\n",
      "2         Scholarship negotiation success stories      2  0.746260\n",
      "3  Columbia ($$$) vs Wharton for entrepreneurship      1  0.741920\n",
      "4            Laptop recommendations for b-school?      2  0.607141\n"
     ]
    }
   ],
   "source": [
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Upendra\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8891/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Jun/2019 18:21:35] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jun/2019 18:21:35] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jun/2019 18:21:35] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jun/2019 18:21:35] \"GET /LDAvis.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jun/2019 18:21:35] code 404, message Not Found\n",
      "127.0.0.1 - - [14/Jun/2019 18:21:35] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis=pyLDAvis.gensim.prepare(lda_model,bow_corpus, dictionary)\n",
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
